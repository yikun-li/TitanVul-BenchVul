"""
Security Consensus Agent for the Vulnerability Fixing Detection Pipeline.

This agent serves as the final arbiter, weighing outputs from both the Auditor
and Critic agents to determine the likelihood of a code change being a vulnerability fix.
"""

import json
import re
from typing import Dict, Any, List

from api.base_client import BaseAPIClient
from utils.logging_utils import LoggerMixin


class ConsensusAgent(LoggerMixin):
    """
    Agent responsible for making final decisions based on Auditor and Critic outputs.

    This agent analyzes both the Auditor's assessment and the Critic's review
    to assign a possibility score for whether the code change is a vulnerability fix.
    """

    def __init__(self, api_client: BaseAPIClient):
        """
        Initialize the Consensus Agent.

        Args:
            api_client: API client for making model calls
        """
        self.api_client = api_client

    def make_final_decision(
            self,
            auditor_output: Dict[str, Any],
            critic_output: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Make the final decision based on Auditor and Critic outputs.

        Args:
            auditor_output: Analysis results from the Auditor Agent
            critic_output: Review results from the Critic Agent

        Returns:
            Dictionary containing final decision and possibility score
        """
        # Create the prompt messages
        messages = self._create_prompt_messages(auditor_output, critic_output)

        # Make the API call
        response = self.api_client.call_model(messages, "Security Consensus")

        # Parse and validate the response
        consensus_result = self._parse_response(response)

        return consensus_result

    def _create_prompt_messages(
            self,
            auditor_output: Dict[str, Any],
            critic_output: Dict[str, Any]
    ) -> List[Dict[str, str]]:
        """
        Create the prompt messages for the API call.

        Args:
            auditor_output: Analysis results from the Auditor Agent
            critic_output: Review results from the Critic Agent

        Returns:
            List of messages for the API call
        """
        system_prompt = """You are the final arbiter, responsible for weighing the outputs of both the Auditor and Critic Agents to determine how likely it is that the code change is attempting to address security vulnerabilities.

* Consider both analyses, especially points of agreement or disagreement, as well as the specific code evidence presented.
* When agents strongly disagree, prioritize concrete evidence over subjective interpretations.
* Assign a possibility score from 0 (definitely not a vuln fix) to 3 (definitely a vuln fix attempt), justify your rating, and highlight any unresolved uncertainties.

Your task:

1. Analyze the arguments and evidence from both agents.
2. Assign a possibility score based on these criteria:
   * 0: Definitely NOT a vulnerability fix (e.g., feature additions, refactoring, performance improvements with no security implications)
   * 1: Unclear or ambiguous (conflicting evidence, insufficient context, or mixed signals about security intent)
   * 2: Probably a vulnerability fix attempt (security-related changes with some ambiguity about specific vulnerabilities addressed)
   * 3: Definitely a vulnerability fix attempt (clear security patches, explicit vulnerability remediation, or widely recognized security patterns)
3. Explain your reasoning and summarize the most critical supporting or conflicting points.
4. If agents disagree significantly, explain which evidence you find more compelling and why.

**Respond in this exact JSON structure:**

{
  "possibility_score": 0-3,
  "reason": "...",
  "critical_points": [
    "..."
  ]
}"""

        user_prompt = f"""You are given the outputs from both the Auditor and Critic Agents. Please make your final decision about whether this code change is a vulnerability fix.

**Auditor Agent's output:**
{json.dumps(auditor_output, indent=2)}

**Critic Agent's output:**
{json.dumps(critic_output, indent=2)}

Provide your consensus decision following the JSON structure specified in the system prompt."""

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

    def _parse_response(self, response: str) -> Dict[str, Any]:
        """
        Parse the API response and extract JSON data.

        Args:
            response: Raw response from the API

        Returns:
            Parsed JSON data as dictionary
        """
        try:
            # Try to parse as direct JSON first
            consensus_data = json.loads(response)
            return consensus_data
        except json.JSONDecodeError:
            # Try to extract JSON from code blocks
            json_match = re.search(r'```json\n(.*?)\n```', response, re.DOTALL)
            if json_match:
                try:
                    consensus_data = json.loads(json_match.group(1))
                    return consensus_data
                except json.JSONDecodeError:
                    pass

            # Try to find JSON in curly braces
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    consensus_data = json.loads(json_match.group(0))
                    return consensus_data
                except json.JSONDecodeError:
                    pass

            # Special handling for consensus score extraction if still in raw format
            score_match = re.search(r'"possibility_score":\s*(\d)', response)
            if score_match:
                consensus_data = {
                    "possibility_score": int(score_match.group(1)),
                    "reason": "Extracted from raw response",
                    "critical_points": ["Score extracted from unparseable response"],
                    "raw_response": response
                }
                return consensus_data

            # If all parsing attempts fail, return default response
            self.logger.error("Could not parse JSON from Consensus response. Raw response:")
            self.logger.error(response)

            # Return a default response if parsing fails
            consensus_data = {
                "possibility_score": -1,
                "reason": "Failed to parse response",
                "critical_points": ["Parse error occurred"],
                "parse_error": "Could not parse JSON response from Consensus",
                "raw_response": response
            }

            return consensus_data

    def extract_json_from_response(self, content: str) -> Dict[str, Any]:
        """
        Extract JSON from markdown code blocks or plain text.

        Args:
            content: Raw content from API response

        Returns:
            Parsed JSON data or raw response if parsing fails
        """
        # Try to extract JSON from markdown code blocks
        json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?```', content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1).strip()
            try:
                return json.loads(json_str)
            except json.JSONDecodeError:
                pass

        # Try to parse the entire content as JSON
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass

        # Special handling for consensus score extraction if still in raw format
        score_match = re.search(r'"possibility_score":\s*(\d)', content)
        if score_match:
            return {
                "possibility_score": int(score_match.group(1)),
                "reason": "Extracted from raw response",
                "critical_points": ["Score extracted from unparseable response"],
                "raw_response": content
            }

        # If all fails, return as raw response
        return {"raw_response": content}
