"""
Configuration management for the Vulnerability Fixing Detection Pipeline.

This module handles all configuration settings, environment variables,
and default values for the vulnerability fixing detection pipeline.
"""

import os
from typing import Dict, List, Optional, Literal
from dataclasses import dataclass


@dataclass
class ModelConfig:
    """Configuration for model providers and their settings."""
    provider: Literal["openai", "anthropic"] = "openai"
    model: str = "gpt-4o"
    temperature: float = 0.0  # Changed to 0.0 for more deterministic analysis
    max_tokens: int = 4000


@dataclass
class PipelineConfig:
    """Configuration for the vulnerability detection pipeline."""
    output_dir: str = "_output"
    input_file: str = "input_data.csv"
    use_diff_format: bool = False
    include_commit_message: bool = True
    restart_interval: int = 20  # minutes
    disable_restart: bool = False
    batch_size: int = 100  # Number of samples to process in each batch

    def __post_init__(self):
        """Validate configuration after initialization."""
        if not os.path.exists(self.input_file):
            raise ValueError(f"Input file {self.input_file} does not exist")


@dataclass
class APICredentials:
    """API credentials for different providers."""
    openai_api_key: Optional[str] = None
    anthropic_api_key: Optional[str] = None

    def __post_init__(self):
        """Load API keys from environment variables if not provided."""
        if not self.openai_api_key:
            self.openai_api_key = os.environ.get("OPENAI_API_KEY")

        if not self.anthropic_api_key:
            self.anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")


class DetectionConfig:
    """Configuration for vulnerability detection analysis."""

    # Consensus scoring scale
    CONSENSUS_SCORES = {
        0: "Definitely NOT a vulnerability fix",
        1: "Unclear or ambiguous",
        2: "Probably a vulnerability fix attempt",
        3: "Definitely a vulnerability fix attempt"
    }

    # Common CWE types that might be analyzed
    COMMON_CWE_TYPES = {
        "22": "Path Traversal",
        "77": "Command Injection",
        "79": "Cross-site Scripting",
        "89": "SQL Injection",
        "94": "Code Injection",
        "125": "Out-of-bounds Read",
        "787": "Out-of-bounds Write",
        "190": "Integer Overflow or Wraparound",
        "200": "Exposure of Sensitive Information",
        "269": "Improper Privilege Management",
        "306": "Missing Authentication for Critical Function",
        "798": "Use of Hard-coded Credentials",
        "352": "Cross-Site Request Forgery (CSRF)",
        "918": "Server-Side Request Forgery (SSRF)",
        "400": "Uncontrolled Resource Consumption",
        "416": "Use After Free",
        "434": "Unrestricted Upload of File with Dangerous Type",
        "476": "NULL Pointer Dereference",
        "502": "Deserialization of Untrusted Data",
        "862": "Missing Authorization",
        "863": "Incorrect Authorization",
    }

    # Expected CSV input columns
    REQUIRED_CSV_COLUMNS = [
        "func_before",
        "func_after",
        "commit_message",
        "cwe_id"
    ]

    # Output CSV columns
    OUTPUT_CSV_COLUMNS = [
        "func_before",
        "func_after",
        "commit_message",
        "cwe_id",
        "auditor_result",
        "critic_result",
        "consensus_score",
        "consensus_result",
        "full_analysis"
    ]


def load_config(
        provider: str = "openai",
        model: str = "gpt-4o",
        temperature: float = 0.0,
        output_dir: str = "_output",
        input_file: str = "input_data.csv",
        use_diff_format: bool = False,
        include_commit_message: bool = True,
        restart_interval: int = 20,
        disable_restart: bool = False,
        batch_size: int = 100
) -> tuple[ModelConfig, PipelineConfig, APICredentials]:
    """
    Load and validate configuration from parameters and environment.

    Args:
        provider: Model provider ('openai' or 'anthropic')
        model: Model name to use
        temperature: Temperature for text generation (0.0 for deterministic)
        output_dir: Directory for output files
        input_file: Path to input CSV file
        use_diff_format: Whether to use diff format for code changes
        include_commit_message: Whether to include commit message in analysis
        restart_interval: Restart interval in minutes
        disable_restart: Whether to disable automatic restart
        batch_size: Number of samples to process in each batch

    Returns:
        Tuple of (ModelConfig, PipelineConfig, APICredentials)

    Raises:
        ValueError: If required API keys are missing or input file doesn't exist
    """
    # Create configuration objects
    model_config = ModelConfig(
        provider=provider,
        model=model,
        temperature=temperature
    )

    pipeline_config = PipelineConfig(
        output_dir=output_dir,
        input_file=input_file,
        use_diff_format=use_diff_format,
        include_commit_message=include_commit_message,
        restart_interval=restart_interval,
        disable_restart=disable_restart,
        batch_size=batch_size
    )

    api_credentials = APICredentials()

    # Validate API credentials based on provider
    if provider == "openai" and not api_credentials.openai_api_key:
        raise ValueError(
            "OpenAI API key is required. Please set OPENAI_API_KEY environment variable "
            "or provide it directly."
        )
    elif provider == "anthropic" and not api_credentials.anthropic_api_key:
        raise ValueError(
            "Anthropic API key is required. Please set ANTHROPIC_API_KEY environment variable "
            "or provide it directly."
        )

    return model_config, pipeline_config, api_credentials
