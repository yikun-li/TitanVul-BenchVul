"""
CSV file utilities for the Vulnerability Fixing Detection Pipeline.

This module provides utilities for CSV file operations, result saving,
and progress tracking across pipeline runs.
"""

import os
import csv
import json
import time
import sys
from typing import Dict, Any, Set, Tuple, List, Optional, Iterator

from utils.logging_utils import get_logger

# Set CSV field size limit to handle large code snippets
csv.field_size_limit(sys.maxsize)

logger = get_logger(__name__)


class CSVFileManager:
    """Manages CSV file operations for the vulnerability detection pipeline."""

    def __init__(self, output_dir: str = "_output"):
        """
        Initialize the CSV file manager.

        Args:
            output_dir: Directory to store output files
        """
        self.output_dir = output_dir
        self.progress_file = os.path.join(output_dir, "detection_progress.json")

        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"Output directory: {os.path.abspath(output_dir)}")

    def read_input_csv(self, input_file: str) -> Iterator[Dict[str, str]]:
        """
        Read input CSV file and yield rows.

        Args:
            input_file: Path to input CSV file

        Yields:
            Dictionary representing each CSV row

        Raises:
            FileNotFoundError: If input file doesn't exist
            ValueError: If required columns are missing
        """
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"Input file {input_file} does not exist")

        required_columns = ["func_before", "func_after", "commit_message", "cwe_id"]

        with open(input_file, mode='r', encoding='utf-8') as file:
            reader = csv.DictReader(file)

            # Validate required columns
            missing_columns = [col for col in required_columns if col not in reader.fieldnames]
            if missing_columns:
                raise ValueError(f"Missing required columns: {missing_columns}")

            for row in reader:
                yield row

    def count_csv_rows(self, input_file: str) -> int:
        """
        Count total rows in CSV file.

        Args:
            input_file: Path to input CSV file

        Returns:
            Number of rows in the file
        """
        if not os.path.exists(input_file):
            return 0

        with open(input_file, mode='r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            return sum(1 for _ in reader)

    def get_processed_identifiers(self, output_file: str) -> Set[str]:
        """
        Get set of already processed sample identifiers.

        Args:
            output_file: Path to output CSV file

        Returns:
            Set of processed sample identifiers
        """
        processed_ids = set()

        if not os.path.exists(output_file):
            return processed_ids

        try:
            with open(output_file, mode='r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    # Create identifier from key fields
                    identifier = self._create_identifier(
                        row.get('func_before', ''),
                        row.get('func_after', ''),
                        row.get('commit_message', ''),
                        row.get('cwe_id', '')
                    )
                    processed_ids.add(identifier)
        except Exception as e:
            logger.warning(f"Error reading processed identifiers: {e}")

        logger.info(f"Found {len(processed_ids)} already processed samples")
        return processed_ids

    def _create_identifier(self, func_before: str, func_after: str,
                           commit_message: str, cwe_id: str) -> str:
        """
        Create unique identifier for a sample.

        Args:
            func_before: Original function code
            func_after: Modified function code
            commit_message: Commit message
            cwe_id: CWE identifier

        Returns:
            Unique identifier string
        """
        return func_before + func_after + commit_message + cwe_id

    def initialize_output_csv(self, output_file: str) -> None:
        """
        Initialize output CSV file with headers if it doesn't exist.

        Args:
            output_file: Path to output CSV file
        """
        if not os.path.exists(output_file):
            fieldnames = [
                'func_before',
                'func_after',
                'commit_message',
                'cwe_id',
                'auditor_result',
                'critic_result',
                'consensus_score',
                'consensus_result',
                'full_analysis'
            ]

            with open(output_file, mode='w', newline='', encoding='utf-8') as file:
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                writer.writeheader()

            logger.info(f"Initialized output CSV file: {output_file}")

    def write_csv_row(self, output_file: str, row_data: Dict[str, Any]) -> None:
        """
        Write a single row to the output CSV file.

        Args:
            output_file: Path to output CSV file
            row_data: Dictionary containing row data
        """
        fieldnames = [
            'func_before',
            'func_after',
            'commit_message',
            'cwe_id',
            'auditor_result',
            'critic_result',
            'consensus_score',
            'consensus_result',
            'full_analysis'
        ]

        with open(output_file, mode='a', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writerow(row_data)

    def save_batch_results(self, output_file: str, batch_results: List[Dict[str, Any]]) -> None:
        """
        Save a batch of results to the output CSV file.

        Args:
            output_file: Path to output CSV file
            batch_results: List of result dictionaries
        """
        fieldnames = [
            'func_before',
            'func_after',
            'commit_message',
            'cwe_id',
            'auditor_result',
            'critic_result',
            'consensus_score',
            'consensus_result',
            'full_analysis'
        ]

        with open(output_file, mode='a', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writerows(batch_results)

        logger.info(f"Saved batch of {len(batch_results)} results to {output_file}")

    def save_progress(self, progress_data: Dict[str, Any]) -> None:
        """
        Save progress information to track detection state.

        Args:
            progress_data: Dictionary containing progress information
        """
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, indent=2)

    def load_progress(self) -> Optional[Dict[str, Any]]:
        """
        Load progress information from the progress file.

        Returns:
            Progress data if file exists, None otherwise
        """
        if not os.path.exists(self.progress_file):
            return None

        try:
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Error reading progress file: {str(e)}")
            return None

    def cleanup_progress(self) -> None:
        """Remove the progress file when detection is complete."""
        if os.path.exists(self.progress_file):
            os.remove(self.progress_file)
            logger.info("Progress file cleaned up.")

    def get_consensus_score_distribution(self, output_file: str) -> Dict[int, int]:
        """
        Get distribution of consensus scores from output file.

        Args:
            output_file: Path to output CSV file

        Returns:
            Dictionary mapping consensus scores to their counts
        """
        score_distribution = {0: 0, 1: 0, 2: 0, 3: 0, -1: 0}  # -1 for errors

        if not os.path.exists(output_file):
            return score_distribution

        try:
            with open(output_file, mode='r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    score = int(row.get('consensus_score', -1))
                    score_distribution[score] = score_distribution.get(score, 0) + 1
        except Exception as e:
            logger.error(f"Error reading consensus scores: {e}")

        return score_distribution

    def generate_summary_report(self, output_file: str) -> Dict[str, Any]:
        """
        Generate a summary report of the detection results.

        Args:
            output_file: Path to output CSV file

        Returns:
            Dictionary containing summary statistics
        """
        if not os.path.exists(output_file):
            return {"error": "Output file not found"}

        total_samples = 0
        consensus_distribution = {0: 0, 1: 0, 2: 0, 3: 0, -1: 0}
        cwe_counts = {}

        try:
            with open(output_file, mode='r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    total_samples += 1

                    # Count consensus scores
                    score = int(row.get('consensus_score', -1))
                    consensus_distribution[score] += 1

                    # Count CWE types
                    cwe_id = row.get('cwe_id', 'Unknown')
                    cwe_counts[cwe_id] = cwe_counts.get(cwe_id, 0) + 1

        except Exception as e:
            logger.error(f"Error generating summary report: {e}")
            return {"error": str(e)}

        # Calculate percentages
        consensus_percentages = {}
        for score, count in consensus_distribution.items():
            percentage = (count / total_samples * 100) if total_samples > 0 else 0
            consensus_percentages[score] = f"{percentage:.1f}%"

        return {
            "total_samples": total_samples,
            "consensus_distribution": consensus_distribution,
            "consensus_percentages": consensus_percentages,
            "cwe_distribution": dict(sorted(cwe_counts.items(), key=lambda x: x[1], reverse=True)[:10]),
            "vuln_fix_candidates": consensus_distribution[2] + consensus_distribution[3],
            "non_vuln_fixes": consensus_distribution[0],
            "uncertain_cases": consensus_distribution[1]
        }

    def create_filtered_output(self, input_file: str, output_file: str,
                               min_consensus_score: int = 2) -> str:
        """
        Create a filtered output file with only high-confidence vulnerability fixes.

        Args:
            input_file: Path to input CSV file with results
            output_file: Path for filtered output file
            min_consensus_score: Minimum consensus score to include

        Returns:
            Path to the filtered output file
        """
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"Input file {input_file} does not exist")

        filtered_count = 0

        with open(input_file, mode='r', encoding='utf-8') as infile:
            reader = csv.DictReader(infile)

            with open(output_file, mode='w', newline='', encoding='utf-8') as outfile:
                writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)
                writer.writeheader()

                for row in reader:
                    score = int(row.get('consensus_score', -1))
                    if score >= min_consensus_score:
                        writer.writerow(row)
                        filtered_count += 1

        logger.info(f"Created filtered output with {filtered_count} high-confidence samples")
        return output_file
